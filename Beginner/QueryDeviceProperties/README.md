
- [ ] Here is a good place to explain the basic concepts of blocks, threads, register, shared etc.
- [ ] Possibly extend this chapter to discuss contexts.


# Query Device Properties
- [ ] complete: 
The CUDA runtime API is ...

## Learning Outcomes
1. Using the CUDA runtime API to acquire information about the device currently in use. 

# DoD
1. Use the CUDA runtime API to acquire the current device ID.
2. Use the CUDA runtime API to question your device's properties.
   - [ ] Bonus: repeat the same process using cuda driver api (hint: `-lcuda`)

# Material & Setup
- [ ] todo

## Gil's notes on CUDA runtime API
- [ ] edit
We as GPU programmers need an interface between the host and the device. 
There are two levels of nterface, the CUDA runtime API provides a more high level control while the CUDA driver API provides more involved, low level control. For example, context management is not possible using only the runtime API and needs the driver API.

There is a concept of "primary context" which is the context automatically generated by the runtime API, one per process per device (if you have two processes and one device = two contexts). 

cudaDeviceSynchronize() and cudaDeviceReset() are two runtime API calls that work on the primary context.

### About synchronization
- kernel calls are always asynchronous.
- memset also (except when target is pinned host memory).
- 



## Related Reading Material
- CUDA runtime API reference https://docs.nvidia.com/cuda/pdf/CUDA_Runtime_API.pdf
- But it is way cooler to view the source code directly at `/usr/local/cuda/include/cuda_runtime_api.h`

